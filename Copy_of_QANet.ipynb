{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of QANet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balasundaramc/Python-and-OOP/blob/master/Copy_of_QANet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir5INwRPrIY3",
        "colab_type": "code",
        "outputId": "2117e97f-6744-4f13-bac1-94729885777b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/NLPLearn/QANet.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'QANet'...\n",
            "remote: Enumerating objects: 176, done.\u001b[K\n",
            "remote: Total 176 (delta 0), reused 0 (delta 0), pack-reused 176\u001b[K\n",
            "Receiving objects: 100% (176/176), 357.63 KiB | 4.53 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd0bTM4erSE6",
        "colab_type": "code",
        "outputId": "0cb1588b-7468-49e8-b563-0336ebed8741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "!sh QANet/download.sh"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-17 09:18:18--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.111.153, 185.199.108.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30288272 (29M) [application/json]\n",
            "Saving to: ‘/content/datasets/squad/train-v1.1.json’\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r         /content/d  95%[==================> ]  27.64M   138MB/s               \r/content/datasets/s 100%[===================>]  28.88M   139MB/s    in 0.2s    \n",
            "\n",
            "2019-06-17 09:18:18 (139 MB/s) - ‘/content/datasets/squad/train-v1.1.json’ saved [30288272/30288272]\n",
            "\n",
            "--2019-06-17 09:18:18--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.111.153, 185.199.108.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4854279 (4.6M) [application/json]\n",
            "Saving to: ‘/content/datasets/squad/dev-v1.1.json’\n",
            "\n",
            "/content/datasets/s 100%[===================>]   4.63M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-06-17 09:18:18 (53.5 MB/s) - ‘/content/datasets/squad/dev-v1.1.json’ saved [4854279/4854279]\n",
            "\n",
            "--2019-06-17 09:18:18--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2019-06-17 09:18:18--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2019-06-17 09:18:18--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘/content/datasets/glove/glove.840B.300d.zip’\n",
            "\n",
            "/content/datasets/g 100%[===================>]   2.03G  65.6MB/s    in 33s     \n",
            "\n",
            "2019-06-17 09:18:52 (62.3 MB/s) - ‘/content/datasets/glove/glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n",
            "Archive:  /content/datasets/glove/glove.840B.300d.zip\n",
            "  inflating: /content/datasets/glove/glove.840B.300d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yCp4Vslr-aw",
        "colab_type": "code",
        "outputId": "1adb3806-f21e-4e62-b40c-b8ba9fa70a01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "!python QANet/config.py --mode prepro"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0617 10:54:35.952240 140485775136640 deprecation_wrapper.py:119] From QANet/config.py:144: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "Generating train examples...\n",
            "  0% 2/442 [00:00<02:54,  2.52it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"QANet/config.py\", line 144, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"QANet/config.py\", line 127, in main\n",
            "    prepro(config)\n",
            "  File \"/content/QANet/prepro.py\", line 275, in prepro\n",
            "    config.train_file, \"train\", word_counter, char_counter)\n",
            "  File \"/content/QANet/prepro.py\", line 58, in process_file\n",
            "    ques_tokens = word_tokenize(ques)\n",
            "  File \"/content/QANet/prepro.py\", line 19, in word_tokenize\n",
            "    doc = nlp(sent)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/language.py\", line 382, in __call__\n",
            "    doc = self.make_doc(text)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/language.py\", line 406, in make_doc\n",
            "    return self.tokenizer(text)\n",
            "  File \"tokenizer.pyx\", line 89, in spacy.tokenizer.Tokenizer.__call__\n",
            "  File \"doc.pyx\", line 194, in spacy.tokens.doc.Doc.__init__\n",
            "  File \"doc.pyx\", line 73, in spacy.tokens.doc._get_chunker\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/util.py\", line 61, in get_lang_class\n",
            "    entry_point = get_entry_point(\"spacy_languages\", lang)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/util.py\", line 260, in get_entry_point\n",
            "    for entry_point in pkg_resources.iter_entry_points(key):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\", line 656, in <genexpr>\n",
            "    for entry in dist.get_entry_map(group).values()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\", line 2854, in get_entry_map\n",
            "    return ep_map.get(group, {})\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXejbsRVt8k1",
        "colab_type": "code",
        "outputId": "f5960e8f-3856-4ce2-8568-6001b28c4524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6905
        }
      },
      "source": [
        "!python QANet/config.py --mode debug"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0617 10:54:52.565936 139753355192192 deprecation_wrapper.py:119] From QANet/config.py:144: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "Building model...\n",
            "W0617 10:55:14.084150 139753355192192 deprecation_wrapper.py:119] From /content/QANet/util.py:17: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0617 10:55:14.084484 139753355192192 deprecation_wrapper.py:119] From /content/QANet/util.py:19: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0617 10:55:14.172995 139753355192192 deprecation_wrapper.py:119] From /content/QANet/main.py:37: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0617 10:55:14.173914 139753355192192 deprecation_wrapper.py:119] From /content/QANet/main.py:38: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
            "\n",
            "W0617 10:55:14.174127 139753355192192 deprecation.py:323] From /content/QANet/main.py:39: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
            "W0617 10:55:14.174306 139753355192192 deprecation.py:323] From /content/QANet/main.py:39: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
            "W0617 10:55:14.179824 139753355192192 deprecation.py:323] From /content/QANet/main.py:40: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "W0617 10:55:14.211129 139753355192192 deprecation_wrapper.py:119] From /content/QANet/model.py:11: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0617 10:55:14.215410 139753355192192 deprecation_wrapper.py:119] From /content/QANet/model.py:13: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0617 10:55:14.714952 139753355192192 deprecation.py:506] From /content/QANet/model.py:77: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0617 10:55:15.036109 139753355192192 deprecation.py:323] From /content/QANet/layers.py:365: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0617 10:55:16.124094 139753355192192 deprecation.py:506] From /content/QANet/model.py:134: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n",
            "W0617 10:55:23.426430 139753355192192 deprecation.py:323] From /content/QANet/model.py:174: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0617 10:55:23.791469 139753355192192 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "Total number of trainable parameters: 788673\n",
            "W0617 10:55:28.338534 139753355192192 deprecation_wrapper.py:119] From /content/QANet/model.py:60: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0617 10:55:49.237079 139753355192192 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2019-06-17 10:55:51.674190: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-06-17 10:55:51.674793: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b80700 executing computations on platform Host. Devices:\n",
            "2019-06-17 10:55:51.674846: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "W0617 10:55:51.701699 139753355192192 deprecation_wrapper.py:119] From /content/QANet/main.py:54: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "2019-06-17 10:55:53.489419: W tensorflow/core/framework/allocator.cc:107] Allocation of 109962000 exceeds 10% of system memory.\n",
            "2019-06-17 10:55:53.670368: W tensorflow/core/framework/allocator.cc:107] Allocation of 109962000 exceeds 10% of system memory.\n",
            "2019-06-17 10:55:54.048535: W tensorflow/core/framework/allocator.cc:107] Allocation of 109962000 exceeds 10% of system memory.\n",
            "2019-06-17 10:55:54.413071: W tensorflow/core/framework/allocator.cc:107] Allocation of 109962000 exceeds 10% of system memory.\n",
            "2019-06-17 10:55:54.858628: W tensorflow/core/framework/allocator.cc:107] Allocation of 109962000 exceeds 10% of system memory.\n",
            "2019-06-17 10:55:56.133085: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "W0617 10:55:56.730497 139753355192192 deprecation_wrapper.py:119] From /content/QANet/main.py:56: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0617 10:55:59.846236 139753355192192 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0617 10:55:59.847307 139753355192192 saver.py:1280] Restoring parameters from train/FRC/model/model_2.ckpt\n",
            "  0% 0/1 [00:00<?, ?it/s]2019-06-17 10:56:47.093895: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 7993 of 15000\n",
            "2019-06-17 10:56:55.800930: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:11<00:00, 11.25s/it]\u001b[A\n",
            "\u001b[A\n",
            "  0% 0/328 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 1/328 [00:06<37:16,  6.84s/it]\u001b[A\n",
            "  1% 2/328 [00:11<33:06,  6.09s/it]\u001b[A\n",
            "  1% 3/328 [00:18<34:37,  6.39s/it]\u001b[A\n",
            "  1% 4/328 [00:22<31:11,  5.78s/it]\u001b[A\n",
            "  2% 5/328 [00:28<30:49,  5.73s/it]\u001b[A\n",
            "  2% 6/328 [00:33<29:29,  5.49s/it]\u001b[A\n",
            "  2% 7/328 [00:36<26:42,  4.99s/it]\u001b[A\n",
            "  2% 8/328 [00:40<23:55,  4.49s/it]\u001b[A\n",
            "  3% 9/328 [00:43<22:26,  4.22s/it]\u001b[A\n",
            "  3% 10/328 [00:49<24:14,  4.57s/it]\u001b[A\n",
            "  3% 11/328 [00:55<27:16,  5.16s/it]\u001b[A\n",
            "  4% 12/328 [01:00<26:36,  5.05s/it]\u001b[A\n",
            "  4% 13/328 [01:03<23:37,  4.50s/it]\u001b[A\n",
            "  4% 14/328 [01:10<27:17,  5.21s/it]\u001b[A\n",
            "  5% 15/328 [01:16<27:35,  5.29s/it]\u001b[A\n",
            "  5% 16/328 [01:20<25:29,  4.90s/it]\u001b[A\n",
            "  5% 17/328 [01:25<26:11,  5.05s/it]\u001b[A\n",
            "  5% 18/328 [01:29<23:47,  4.60s/it]\u001b[A\n",
            "  6% 19/328 [01:36<27:42,  5.38s/it]\u001b[A\n",
            "  6% 20/328 [01:40<25:25,  4.95s/it]\u001b[A\n",
            "  6% 21/328 [01:48<29:41,  5.80s/it]\u001b[A\n",
            "  7% 22/328 [01:54<31:02,  6.09s/it]\u001b[A\n",
            "  7% 23/328 [01:58<27:36,  5.43s/it]\u001b[A\n",
            "  7% 24/328 [02:04<28:00,  5.53s/it]\u001b[A\n",
            "  8% 25/328 [02:11<29:56,  5.93s/it]\u001b[A\n",
            "  8% 26/328 [02:15<27:24,  5.44s/it]\u001b[A\n",
            "  8% 27/328 [02:19<25:08,  5.01s/it]\u001b[A\n",
            "  9% 28/328 [02:23<23:54,  4.78s/it]\u001b[A\n",
            "  9% 29/328 [02:28<23:28,  4.71s/it]\u001b[A\n",
            "  9% 30/328 [02:34<24:47,  4.99s/it]\u001b[A\n",
            "  9% 31/328 [02:38<23:49,  4.81s/it]\u001b[A\n",
            " 10% 32/328 [02:45<27:05,  5.49s/it]\u001b[A\n",
            " 10% 33/328 [02:49<24:33,  4.99s/it]\u001b[A\n",
            " 10% 34/328 [02:56<26:56,  5.50s/it]\u001b[A\n",
            " 11% 35/328 [03:00<25:26,  5.21s/it]\u001b[A\n",
            " 11% 36/328 [03:03<21:58,  4.52s/it]\u001b[A\n",
            " 11% 37/328 [03:07<20:23,  4.21s/it]\u001b[A\n",
            " 12% 38/328 [03:11<20:52,  4.32s/it]\u001b[A\n",
            " 12% 39/328 [03:15<20:50,  4.33s/it]\u001b[A\n",
            " 12% 40/328 [03:21<23:09,  4.82s/it]\u001b[A\n",
            " 12% 41/328 [03:27<24:42,  5.17s/it]\u001b[A\n",
            " 13% 42/328 [03:34<26:23,  5.54s/it]\u001b[A\n",
            " 13% 43/328 [03:38<25:00,  5.27s/it]\u001b[A\n",
            " 13% 44/328 [03:42<23:09,  4.89s/it]\u001b[A\n",
            " 14% 45/328 [03:49<26:07,  5.54s/it]\u001b[A\n",
            " 14% 46/328 [03:55<26:22,  5.61s/it]\u001b[A\n",
            " 14% 47/328 [04:00<25:04,  5.36s/it]\u001b[A\n",
            " 15% 48/328 [04:06<25:35,  5.48s/it]\u001b[A\n",
            " 15% 49/328 [04:09<22:47,  4.90s/it]\u001b[A\n",
            " 15% 50/328 [04:13<21:13,  4.58s/it]\u001b[A\n",
            " 16% 51/328 [04:20<24:11,  5.24s/it]\u001b[A\n",
            " 16% 52/328 [04:25<23:43,  5.16s/it]\u001b[A\n",
            " 16% 53/328 [04:28<20:24,  4.45s/it]\u001b[A\n",
            " 16% 54/328 [04:34<23:20,  5.11s/it]\u001b[A\n",
            " 17% 55/328 [04:38<21:25,  4.71s/it]\u001b[A\n",
            " 17% 56/328 [04:43<20:57,  4.62s/it]\u001b[A\n",
            " 17% 57/328 [04:46<18:59,  4.21s/it]\u001b[A\n",
            " 18% 58/328 [04:50<18:40,  4.15s/it]\u001b[A\n",
            " 18% 59/328 [04:57<22:37,  5.05s/it]\u001b[A\n",
            " 18% 60/328 [05:04<25:01,  5.60s/it]\u001b[A\n",
            " 19% 61/328 [05:09<23:49,  5.36s/it]\u001b[A\n",
            " 19% 62/328 [05:13<22:55,  5.17s/it]\u001b[A\n",
            " 19% 63/328 [05:17<20:36,  4.67s/it]\u001b[A\n",
            " 20% 64/328 [05:21<19:47,  4.50s/it]\u001b[A\n",
            " 20% 65/328 [05:26<20:54,  4.77s/it]\u001b[A\n",
            " 20% 66/328 [05:31<21:01,  4.82s/it]\u001b[A\n",
            " 20% 67/328 [05:36<20:24,  4.69s/it]\u001b[A\n",
            " 21% 68/328 [05:41<20:35,  4.75s/it]\u001b[A\n",
            " 21% 69/328 [05:44<19:13,  4.45s/it]\u001b[A\n",
            " 21% 70/328 [05:49<19:52,  4.62s/it]\u001b[A\n",
            " 22% 71/328 [05:55<21:16,  4.97s/it]\u001b[A\n",
            " 22% 72/328 [06:01<22:35,  5.30s/it]\u001b[A\n",
            " 22% 73/328 [06:05<20:57,  4.93s/it]\u001b[A\n",
            " 23% 74/328 [06:12<23:09,  5.47s/it]\u001b[A\n",
            " 23% 75/328 [06:16<21:38,  5.13s/it]\u001b[A\n",
            " 23% 76/328 [06:21<21:11,  5.05s/it]\u001b[A\n",
            " 23% 77/328 [06:25<19:31,  4.67s/it]\u001b[A\n",
            " 24% 78/328 [06:31<21:36,  5.19s/it]\u001b[A\n",
            " 24% 79/328 [06:35<19:19,  4.66s/it]\u001b[A\n",
            " 24% 80/328 [06:41<20:35,  4.98s/it]\u001b[A\n",
            " 25% 81/328 [06:46<20:36,  5.00s/it]\u001b[A\n",
            " 25% 82/328 [06:51<21:07,  5.15s/it]\u001b[A\n",
            " 25% 83/328 [06:58<23:29,  5.75s/it]\u001b[A\n",
            " 26% 84/328 [07:03<22:18,  5.49s/it]\u001b[A\n",
            " 26% 85/328 [07:10<23:58,  5.92s/it]\u001b[A\n",
            " 26% 86/328 [07:15<22:54,  5.68s/it]\u001b[A\n",
            " 27% 87/328 [07:20<21:19,  5.31s/it]\u001b[A\n",
            " 27% 88/328 [07:25<21:13,  5.31s/it]\u001b[A\n",
            " 27% 89/328 [07:30<21:09,  5.31s/it]\u001b[A\n",
            " 27% 90/328 [07:35<20:27,  5.16s/it]\u001b[A\n",
            " 28% 91/328 [07:39<19:05,  4.83s/it]\u001b[A\n",
            " 28% 92/328 [07:45<20:15,  5.15s/it]\u001b[A\n",
            " 28% 93/328 [07:48<18:03,  4.61s/it]\u001b[A\n",
            " 29% 94/328 [07:56<20:55,  5.37s/it]\u001b[A\n",
            " 29% 95/328 [08:00<19:42,  5.07s/it]\u001b[A\n",
            " 29% 96/328 [08:04<18:26,  4.77s/it]\u001b[A\n",
            " 30% 97/328 [08:08<18:00,  4.68s/it]\u001b[A\n",
            " 30% 98/328 [08:13<18:00,  4.70s/it]\u001b[A\n",
            " 30% 99/328 [08:19<18:41,  4.90s/it]\u001b[A\n",
            " 30% 100/328 [08:23<18:08,  4.77s/it]\u001b[A\n",
            " 31% 101/328 [08:27<17:04,  4.51s/it]\u001b[A\n",
            " 31% 102/328 [08:31<16:31,  4.39s/it]\u001b[A\n",
            " 31% 103/328 [08:35<16:25,  4.38s/it]\u001b[A\n",
            " 32% 104/328 [08:40<16:27,  4.41s/it]\u001b[A\n",
            " 32% 105/328 [08:44<15:31,  4.18s/it]\u001b[A\n",
            " 32% 106/328 [08:48<15:36,  4.22s/it]\u001b[A\n",
            " 33% 107/328 [08:52<15:24,  4.18s/it]\u001b[A\n",
            " 33% 108/328 [08:59<18:26,  5.03s/it]\u001b[A\n",
            " 33% 109/328 [09:06<20:09,  5.52s/it]\u001b[A\n",
            " 34% 110/328 [09:12<20:41,  5.70s/it]\u001b[A\n",
            " 34% 111/328 [09:18<21:13,  5.87s/it]\u001b[A\n",
            " 34% 112/328 [09:21<18:17,  5.08s/it]\u001b[A\n",
            " 34% 113/328 [09:27<19:25,  5.42s/it]\u001b[A\n",
            " 35% 114/328 [09:32<18:21,  5.15s/it]\u001b[A\n",
            " 35% 115/328 [09:36<17:35,  4.95s/it]\u001b[A\n",
            " 35% 116/328 [09:41<17:24,  4.93s/it]\u001b[A\n",
            " 36% 117/328 [09:45<16:12,  4.61s/it]\u001b[A\n",
            " 36% 118/328 [09:50<16:33,  4.73s/it]\u001b[A\n",
            " 36% 119/328 [09:55<16:09,  4.64s/it]\u001b[A\n",
            " 37% 120/328 [09:58<15:10,  4.38s/it]\u001b[A\n",
            " 37% 121/328 [10:04<16:08,  4.68s/it]\u001b[A\n",
            " 37% 122/328 [10:09<16:37,  4.84s/it]\u001b[A\n",
            " 38% 123/328 [10:14<16:36,  4.86s/it]\u001b[A\n",
            " 38% 124/328 [10:20<17:22,  5.11s/it]\u001b[A\n",
            " 38% 125/328 [10:24<17:03,  5.04s/it]\u001b[A\n",
            " 38% 126/328 [10:30<17:26,  5.18s/it]\u001b[A\n",
            " 39% 127/328 [10:34<16:17,  4.86s/it]\u001b[A\n",
            " 39% 128/328 [10:39<15:46,  4.73s/it]\u001b[A\n",
            " 39% 129/328 [10:44<16:18,  4.92s/it]\u001b[A\n",
            " 40% 130/328 [10:50<17:06,  5.19s/it]\u001b[A\n",
            " 40% 131/328 [10:53<15:24,  4.69s/it]\u001b[A\n",
            " 40% 132/328 [10:59<16:25,  5.03s/it]\u001b[A\n",
            " 41% 133/328 [11:03<15:35,  4.80s/it]\u001b[A\n",
            " 41% 134/328 [11:07<14:43,  4.55s/it]\u001b[A\n",
            " 41% 135/328 [11:12<14:56,  4.64s/it]\u001b[A\n",
            " 41% 136/328 [11:18<16:07,  5.04s/it]\u001b[A\n",
            " 42% 137/328 [11:24<17:13,  5.41s/it]\u001b[A\n",
            " 42% 138/328 [11:30<17:36,  5.56s/it]\u001b[A\n",
            " 42% 139/328 [11:34<15:59,  5.07s/it]\u001b[A\n",
            " 43% 140/328 [11:40<17:01,  5.43s/it]\u001b[A\n",
            " 43% 141/328 [11:44<15:33,  4.99s/it]\u001b[A\n",
            " 43% 142/328 [11:51<17:10,  5.54s/it]\u001b[A\n",
            " 44% 143/328 [11:55<15:22,  4.98s/it]\u001b[A\n",
            " 44% 144/328 [11:58<13:36,  4.44s/it]\u001b[A\n",
            " 44% 145/328 [12:03<14:00,  4.59s/it]\u001b[A\n",
            " 45% 146/328 [12:07<13:23,  4.41s/it]\u001b[A\n",
            " 45% 147/328 [12:14<15:26,  5.12s/it]\u001b[A\n",
            " 45% 148/328 [12:18<14:16,  4.76s/it]\u001b[A\n",
            " 45% 149/328 [12:22<13:19,  4.47s/it]\u001b[A\n",
            " 46% 150/328 [12:26<13:17,  4.48s/it]\u001b[A\n",
            " 46% 151/328 [12:31<13:33,  4.59s/it]\u001b[A\n",
            " 46% 152/328 [12:37<15:14,  5.20s/it]\u001b[A\n",
            " 47% 153/328 [12:41<13:50,  4.75s/it]\u001b[A\n",
            " 47% 154/328 [12:46<14:14,  4.91s/it]\u001b[A\n",
            " 47% 155/328 [12:51<13:47,  4.78s/it]\u001b[A\n",
            " 48% 156/328 [12:54<12:31,  4.37s/it]\u001b[A\n",
            " 48% 157/328 [12:58<11:48,  4.14s/it]\u001b[A\n",
            " 48% 158/328 [13:04<12:57,  4.57s/it]\u001b[A\n",
            " 48% 159/328 [13:09<13:20,  4.73s/it]\u001b[A\n",
            " 49% 160/328 [13:13<12:45,  4.56s/it]\u001b[A\n",
            " 49% 161/328 [13:17<12:40,  4.55s/it]\u001b[A\n",
            " 49% 162/328 [13:23<13:13,  4.78s/it]\u001b[A\n",
            " 50% 163/328 [13:26<12:16,  4.46s/it]\u001b[A\n",
            " 50% 164/328 [13:31<12:01,  4.40s/it]\u001b[A\n",
            " 50% 165/328 [13:34<11:09,  4.11s/it]\u001b[A\n",
            " 51% 166/328 [13:41<13:26,  4.98s/it]\u001b[A\n",
            " 51% 167/328 [13:45<12:35,  4.69s/it]\u001b[A\n",
            " 51% 168/328 [13:51<13:14,  4.97s/it]\u001b[A\n",
            " 52% 169/328 [13:54<11:43,  4.42s/it]\u001b[A\n",
            " 52% 170/328 [13:57<10:41,  4.06s/it]\u001b[A\n",
            " 52% 171/328 [14:03<11:47,  4.51s/it]\u001b[A\n",
            " 52% 172/328 [14:05<10:16,  3.95s/it]\u001b[A\n",
            " 53% 173/328 [14:11<11:27,  4.44s/it]\u001b[A\n",
            " 53% 174/328 [14:15<11:01,  4.30s/it]\u001b[A\n",
            " 53% 175/328 [14:20<11:15,  4.42s/it]\u001b[A\n",
            " 54% 176/328 [14:24<11:30,  4.55s/it]\u001b[A\n",
            " 54% 177/328 [14:29<11:19,  4.50s/it]\u001b[A\n",
            " 54% 178/328 [14:33<10:42,  4.28s/it]\u001b[A\n",
            " 55% 179/328 [14:39<12:26,  5.01s/it]\u001b[A\n",
            " 55% 180/328 [14:43<11:38,  4.72s/it]\u001b[A\n",
            " 55% 181/328 [14:47<11:04,  4.52s/it]\u001b[A\n",
            " 55% 182/328 [14:51<10:26,  4.29s/it]\u001b[A\n",
            " 56% 183/328 [14:55<09:55,  4.10s/it]\u001b[A\n",
            " 56% 184/328 [15:02<11:48,  4.92s/it]\u001b[A\n",
            " 56% 185/328 [15:05<10:45,  4.51s/it]\u001b[A\n",
            " 57% 186/328 [15:08<09:30,  4.02s/it]\u001b[A\n",
            " 57% 187/328 [15:12<09:33,  4.06s/it]\u001b[A\n",
            " 57% 188/328 [15:19<11:23,  4.88s/it]\u001b[A\n",
            " 58% 189/328 [15:23<10:41,  4.61s/it]\u001b[A\n",
            " 58% 190/328 [15:26<09:43,  4.23s/it]\u001b[A\n",
            " 58% 191/328 [15:31<09:41,  4.24s/it]\u001b[A\n",
            " 59% 192/328 [15:36<10:19,  4.56s/it]\u001b[A\n",
            " 59% 193/328 [15:41<10:33,  4.69s/it]\u001b[A\n",
            " 59% 194/328 [15:45<09:54,  4.44s/it]\u001b[A\n",
            " 59% 195/328 [15:50<10:36,  4.79s/it]\u001b[A\n",
            " 60% 196/328 [15:53<09:14,  4.20s/it]\u001b[A\n",
            " 60% 197/328 [15:58<09:22,  4.29s/it]\u001b[A\n",
            " 60% 198/328 [16:02<09:28,  4.37s/it]\u001b[A\n",
            " 61% 199/328 [16:08<10:30,  4.89s/it]\u001b[A\n",
            " 61% 200/328 [16:13<10:12,  4.78s/it]\u001b[A\n",
            " 61% 201/328 [16:16<09:10,  4.34s/it]\u001b[A\n",
            " 62% 202/328 [16:22<09:55,  4.73s/it]\u001b[A\n",
            " 62% 203/328 [16:27<10:27,  5.02s/it]\u001b[A\n",
            " 62% 204/328 [16:31<09:33,  4.63s/it]\u001b[A\n",
            " 62% 205/328 [16:34<08:33,  4.18s/it]\u001b[A\n",
            " 63% 206/328 [16:38<08:22,  4.12s/it]\u001b[A\n",
            " 63% 207/328 [16:44<09:14,  4.58s/it]\u001b[A\n",
            " 63% 208/328 [16:47<08:14,  4.12s/it]\u001b[A\n",
            " 64% 209/328 [16:54<09:43,  4.90s/it]\u001b[A\n",
            " 64% 210/328 [16:58<08:58,  4.57s/it]\u001b[A\n",
            " 64% 211/328 [17:02<08:53,  4.56s/it]\u001b[A\n",
            " 65% 212/328 [17:07<08:54,  4.61s/it]\u001b[A\n",
            " 65% 213/328 [17:11<08:35,  4.48s/it]\u001b[A\n",
            " 65% 214/328 [17:15<08:16,  4.36s/it]\u001b[A\n",
            " 66% 215/328 [17:20<08:20,  4.43s/it]\u001b[A\n",
            " 66% 216/328 [17:24<08:11,  4.39s/it]\u001b[A\n",
            " 66% 217/328 [17:27<07:37,  4.12s/it]\u001b[A\n",
            " 66% 218/328 [17:32<07:54,  4.31s/it]\u001b[A\n",
            " 67% 219/328 [17:39<09:14,  5.08s/it]\u001b[A\n",
            " 67% 220/328 [17:42<08:14,  4.58s/it]\u001b[A\n",
            " 67% 221/328 [17:47<07:56,  4.46s/it]\u001b[A\n",
            " 68% 222/328 [17:54<09:09,  5.19s/it]\u001b[A\n",
            " 68% 223/328 [17:56<07:54,  4.52s/it]\u001b[A\n",
            " 68% 224/328 [18:01<07:37,  4.40s/it]\u001b[A\n",
            " 69% 225/328 [18:06<07:57,  4.64s/it]\u001b[A\n",
            " 69% 226/328 [18:13<09:04,  5.34s/it]\u001b[A\n",
            " 69% 227/328 [18:17<08:18,  4.94s/it]\u001b[A\n",
            " 70% 228/328 [18:21<07:42,  4.62s/it]\u001b[A\n",
            " 70% 229/328 [18:28<08:47,  5.33s/it]\u001b[A\n",
            " 70% 230/328 [18:35<09:30,  5.82s/it]\u001b[A\n",
            " 70% 231/328 [18:41<09:26,  5.84s/it]\u001b[A\n",
            " 71% 232/328 [18:45<08:53,  5.56s/it]\u001b[A\n",
            " 71% 233/328 [18:52<09:13,  5.82s/it]\u001b[A\n",
            " 71% 234/328 [18:56<08:27,  5.40s/it]\u001b[A\n",
            " 72% 235/328 [19:03<09:05,  5.87s/it]\u001b[A\n",
            " 72% 236/328 [19:07<08:06,  5.29s/it]\u001b[A\n",
            " 72% 237/328 [19:11<07:35,  5.00s/it]\u001b[A\n",
            " 73% 238/328 [19:15<06:56,  4.63s/it]\u001b[A\n",
            " 73% 239/328 [19:19<06:36,  4.46s/it]\u001b[A\n",
            " 73% 240/328 [19:23<06:11,  4.22s/it]\u001b[A\n",
            " 73% 241/328 [19:30<07:07,  4.92s/it]\u001b[A\n",
            " 74% 242/328 [19:34<06:46,  4.73s/it]\u001b[A\n",
            " 74% 243/328 [19:41<07:35,  5.35s/it]\u001b[A\n",
            " 74% 244/328 [19:47<07:48,  5.57s/it]\u001b[A\n",
            " 75% 245/328 [19:54<08:19,  6.01s/it]\u001b[A\n",
            " 75% 246/328 [20:00<08:13,  6.02s/it]\u001b[A\n",
            " 75% 247/328 [20:04<07:15,  5.38s/it]\u001b[A\n",
            " 76% 248/328 [20:09<07:03,  5.30s/it]\u001b[A\n",
            " 76% 249/328 [20:12<06:01,  4.58s/it]\u001b[A\n",
            " 76% 250/328 [20:18<06:40,  5.13s/it]\u001b[A\n",
            " 77% 251/328 [20:24<06:41,  5.22s/it]\u001b[A\n",
            " 77% 252/328 [20:28<06:20,  5.00s/it]\u001b[A\n",
            " 77% 253/328 [20:35<06:50,  5.47s/it]\u001b[A\n",
            " 77% 254/328 [20:37<05:43,  4.64s/it]\u001b[A\n",
            " 78% 255/328 [20:42<05:46,  4.75s/it]\u001b[A\n",
            " 78% 256/328 [20:47<05:32,  4.61s/it]\u001b[A\n",
            " 78% 257/328 [20:51<05:20,  4.51s/it]\u001b[A\n",
            " 79% 258/328 [20:58<06:09,  5.27s/it]\u001b[A\n",
            " 79% 259/328 [21:05<06:32,  5.69s/it]\u001b[A\n",
            " 79% 260/328 [21:10<06:31,  5.76s/it]\u001b[A\n",
            " 80% 261/328 [21:15<05:59,  5.36s/it]\u001b[A\n",
            " 80% 262/328 [21:21<06:06,  5.55s/it]\u001b[A\n",
            " 80% 263/328 [21:25<05:25,  5.01s/it]\u001b[A\n",
            " 80% 264/328 [21:29<05:16,  4.94s/it]\u001b[A\n",
            " 81% 265/328 [21:36<05:38,  5.37s/it]\u001b[A\n",
            " 81% 266/328 [21:41<05:36,  5.43s/it]\u001b[A\n",
            " 81% 267/328 [21:47<05:29,  5.40s/it]\u001b[A\n",
            " 82% 268/328 [21:52<05:26,  5.45s/it]\u001b[A\n",
            " 82% 269/328 [21:58<05:21,  5.45s/it]\u001b[A\n",
            " 82% 270/328 [22:03<05:06,  5.29s/it]\u001b[A\n",
            " 83% 271/328 [22:06<04:34,  4.81s/it]\u001b[A\n",
            " 83% 272/328 [22:10<04:05,  4.38s/it]\u001b[A\n",
            " 83% 273/328 [22:17<04:43,  5.16s/it]\u001b[A\n",
            " 84% 274/328 [22:21<04:17,  4.77s/it]\u001b[A\n",
            " 84% 275/328 [22:25<04:07,  4.66s/it]\u001b[A\n",
            " 84% 276/328 [22:29<03:57,  4.57s/it]\u001b[A\n",
            " 84% 277/328 [22:33<03:45,  4.42s/it]\u001b[A\n",
            " 85% 278/328 [22:40<04:13,  5.07s/it]\u001b[A\n",
            " 85% 279/328 [22:45<04:10,  5.10s/it]\u001b[A\n",
            " 85% 280/328 [22:49<03:41,  4.62s/it]\u001b[A\n",
            " 86% 281/328 [22:53<03:38,  4.64s/it]\u001b[A\n",
            " 86% 282/328 [22:57<03:17,  4.29s/it]\u001b[A\n",
            " 86% 283/328 [23:04<03:47,  5.05s/it]\u001b[A\n",
            " 87% 284/328 [23:07<03:26,  4.69s/it]\u001b[A\n",
            " 87% 285/328 [23:12<03:22,  4.71s/it]\u001b[A\n",
            " 87% 286/328 [23:18<03:30,  5.00s/it]\u001b[A\n",
            " 88% 287/328 [23:22<03:11,  4.67s/it]\u001b[A\n",
            " 88% 288/328 [23:26<03:04,  4.62s/it]\u001b[A\n",
            " 88% 289/328 [23:32<03:15,  5.01s/it]\u001b[A\n",
            " 88% 290/328 [23:38<03:16,  5.18s/it]\u001b[A\n",
            " 89% 291/328 [23:44<03:19,  5.39s/it]\u001b[A\n",
            " 89% 292/328 [23:47<02:56,  4.90s/it]\u001b[A\n",
            " 89% 293/328 [23:51<02:41,  4.62s/it]\u001b[A\n",
            " 90% 294/328 [23:55<02:29,  4.39s/it]\u001b[A\n",
            " 90% 295/328 [24:01<02:35,  4.70s/it]\u001b[A\n",
            " 90% 296/328 [24:05<02:24,  4.52s/it]\u001b[A\n",
            " 91% 297/328 [24:09<02:12,  4.28s/it]\u001b[A\n",
            " 91% 298/328 [24:13<02:10,  4.34s/it]\u001b[A\n",
            " 91% 299/328 [24:18<02:10,  4.49s/it]\u001b[A\n",
            " 91% 300/328 [24:25<02:26,  5.21s/it]\u001b[A\n",
            " 92% 301/328 [24:31<02:29,  5.54s/it]\u001b[A\n",
            " 92% 302/328 [24:36<02:19,  5.35s/it]\u001b[A\n",
            " 92% 303/328 [24:40<02:05,  5.03s/it]\u001b[A\n",
            " 93% 304/328 [24:43<01:47,  4.47s/it]\u001b[A\n",
            " 93% 305/328 [24:49<01:47,  4.68s/it]\u001b[A\n",
            " 93% 306/328 [24:54<01:46,  4.84s/it]\u001b[A\n",
            " 94% 307/328 [24:58<01:35,  4.55s/it]\u001b[A\n",
            " 94% 308/328 [25:01<01:23,  4.18s/it]\u001b[A\n",
            " 94% 309/328 [25:08<01:36,  5.06s/it]\u001b[A\n",
            " 95% 310/328 [25:13<01:27,  4.88s/it]\u001b[A\n",
            " 95% 311/328 [25:16<01:18,  4.59s/it]\u001b[A\n",
            " 95% 312/328 [25:21<01:11,  4.47s/it]\u001b[A\n",
            " 95% 313/328 [25:25<01:06,  4.41s/it]\u001b[A\n",
            " 96% 314/328 [25:32<01:11,  5.13s/it]\u001b[A\n",
            " 96% 315/328 [25:35<00:59,  4.60s/it]\u001b[A\n",
            " 96% 316/328 [25:39<00:54,  4.51s/it]\u001b[A\n",
            " 97% 317/328 [25:43<00:47,  4.28s/it]\u001b[A\n",
            " 97% 318/328 [25:47<00:41,  4.13s/it]\u001b[A\n",
            " 97% 319/328 [25:50<00:34,  3.83s/it]\u001b[A\n",
            " 98% 320/328 [25:55<00:34,  4.26s/it]\u001b[A\n",
            " 98% 321/328 [26:00<00:30,  4.30s/it]\u001b[A\n",
            " 98% 322/328 [26:03<00:24,  4.03s/it]\u001b[A\n",
            " 98% 323/328 [26:06<00:18,  3.79s/it]\u001b[A\n",
            " 99% 324/328 [26:11<00:16,  4.06s/it]\u001b[A\n",
            " 99% 325/328 [26:18<00:14,  4.85s/it]\u001b[A\n",
            " 99% 326/328 [26:22<00:09,  4.73s/it]\u001b[A\n",
            "100% 327/328 [26:28<00:04,  4.92s/it]\u001b[A\n",
            "100% 328/328 [26:33<00:00,  5.06s/it]\u001b[A\n",
            "100% 1/1 [27:48<00:00, 1668.99s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HjG23SXNtsg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1533
        },
        "outputId": "91613182-6348-4012-cd7b-e461a9007ced"
      },
      "source": [
        "!python QANet/config.py --mode demo"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0617 11:34:38.159716 140044370028416 deprecation_wrapper.py:119] From QANet/config.py:144: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0617 11:34:43.689989 140044370028416 deprecation_wrapper.py:119] From /content/QANet/model.py:11: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0617 11:34:43.695658 140044370028416 deprecation_wrapper.py:119] From /content/QANet/model.py:13: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0617 11:34:43.697350 140044370028416 deprecation_wrapper.py:119] From /content/QANet/model.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0617 11:34:44.252538 140044370028416 deprecation_wrapper.py:119] From /content/QANet/model.py:72: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0617 11:34:44.266448 140044370028416 deprecation.py:506] From /content/QANet/model.py:77: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0617 11:34:44.547117 140044370028416 deprecation.py:323] From /content/QANet/layers.py:365: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0617 11:34:44.563527 140044370028416 deprecation_wrapper.py:119] From /content/QANet/layers.py:374: The name tf.mod is deprecated. Please use tf.math.mod instead.\n",
            "\n",
            "W0617 11:34:45.625824 140044370028416 deprecation.py:506] From /content/QANet/model.py:134: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n",
            "W0617 11:34:53.455837 140044370028416 deprecation.py:323] From /content/QANet/model.py:174: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0617 11:34:53.819240 140044370028416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "Total number of trainable parameters: 788673\n",
            "Bottle v0.12.16 server starting up (using WSGIRefServer())...\n",
            "Listening on http://0.0.0.0:8080/\n",
            "Hit Ctrl-C to quit.\n",
            "\n",
            "2019-06-17 11:34:58.964087: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-06-17 11:34:58.964975: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x31c62380 executing computations on platform Host. Devices:\n",
            "2019-06-17 11:34:58.965021: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "Traceback (most recent call last):\n",
            "  File \"QANet/config.py\", line 144, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"QANet/config.py\", line 137, in main\n",
            "    demo(config)\n",
            "  File \"/content/QANet/main.py\", line 130, in demo\n",
            "    demo = Demo(model, config)\n",
            "  File \"/content/QANet/demo.py\", line 50, in __init__\n",
            "    app.run(port=8080, host='0.0.0.0')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bottle.py\", line 755, in run\n",
            "    run(self, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bottle.py\", line 3129, in run\n",
            "    server.run(app)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bottle.py\", line 2781, in run\n",
            "    srv = make_server(self.host, self.port, app, server_cls, handler_cls)\n",
            "  File \"/usr/lib/python3.6/wsgiref/simple_server.py\", line 153, in make_server\n",
            "    server = server_class((host, port), handler_class)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 453, in __init__\n",
            "    self.server_bind()\n",
            "  File \"/usr/lib/python3.6/wsgiref/simple_server.py\", line 50, in server_bind\n",
            "    HTTPServer.server_bind(self)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 136, in server_bind\n",
            "    socketserver.TCPServer.server_bind(self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 467, in server_bind\n",
            "    self.socket.bind(self.server_address)\n",
            "OSError: [Errno 98] Address already in use\n",
            "2019-06-17 11:35:01.435035: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "W0617 11:35:01.851236 140041956284160 deprecation_wrapper.py:119] From /content/QANet/demo.py:73: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0617 11:35:02.198258 140041956284160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0617 11:35:02.199385 140041956284160 saver.py:1280] Restoring parameters from train/FRC/model/model_3.ckpt\n",
            "Exception ignored in: <module 'threading' from '/usr/lib/python3.6/threading.py'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1294, in _shutdown\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}